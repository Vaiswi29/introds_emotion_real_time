{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare_data.py\n",
    "# Import necessary modules\n",
    "#the dataset was taken from kaggle\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import kagglehub\n",
    "from utils import get_face_landmarks\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "#The code downloads a dataset using kagglehub, prints the dataset path and its root contents, and initializes an empty list output to store processed data.\n",
    "path = kagglehub.dataset_download(\"gauravsharma99/fer13-cleaned-dataset\")\n",
    "# Print the dataset path obtained from KaggleHub\n",
    "print(\"Dataset path from KaggleHub:\", path)\n",
    "print(\"Root contents:\", os.listdir(path))\n",
    "output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map class folders to labels (lowercase to handle casing)\n",
    "#we have 7 emotions from the FER-13 dataset but we are only using first five from the cleaned dataset.\n",
    "emotion_to_label = {\n",
    "    'angry': 0,\n",
    "    'disgust': 1,\n",
    "    'fear': 2,\n",
    "    'happy': 3,\n",
    "    'neutral': 4,\n",
    "    'sad': 5,\n",
    "    'surprise': 6\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over folders in the dataset root directory\n",
    "for emotion_label in os.listdir(path):\n",
    "    folder_path = os.path.join(path, emotion_label)\n",
    "    # Skip if the current item is not a directory\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    # Loop over image files in the current emotion folder\n",
    "    for image_file in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        # Read the image using OpenCV\n",
    "        image = cv2.imread(image_path)\n",
    "        # Skip if the image could not be read\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        # Resize the image to 192x192 for MediaPipe compatibility\n",
    "        image = cv2.resize(image, (192, 192))\n",
    "        # Convert grayscale images to BGR format\n",
    "        if len(image.shape) == 2 or image.shape[2] == 1:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "        # Skip images with unexpected channel dimensions\n",
    "        elif image.shape[2] != 3:\n",
    "            print(f\"Skipping image with unexpected shape: {image.shape}\")\n",
    "            continue\n",
    "\n",
    "        # Extract face landmarks using the utility function\n",
    "        face_landmarks = get_face_landmarks(image)\n",
    "        # Check if valid landmarks are detected and the count matches the expected size\n",
    "        if face_landmarks and len(face_landmarks) == 1404:\n",
    "            # Map the folder name (emotion) to its corresponding label index\n",
    "            label_index = emotion_to_label.get(emotion_label.lower())\n",
    "            # If the label index exists, append it to the landmarks and add to the output\n",
    "            if label_index is not None:\n",
    "                face_landmarks.append(label_index)\n",
    "                output.append(face_landmarks)\n",
    "\n",
    "    # Print a message indicating the folder has been processed\n",
    "    print(f\"âœ” Processed emotion folder: {emotion_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report and save\n",
    "label_counts = Counter([sample[-1] for sample in output])\n",
    "print(\"\\nSamples per emotion label:\")\n",
    "for label, count in sorted(label_counts.items()):\n",
    "    name = [k for k, v in emotion_to_label.items() if v == label][0]\n",
    "    print(f\"{label} ({name}): {count}\")\n",
    "\n",
    "np.savetxt(\"data.txt\", np.asarray(output))\n",
    "print(f\"Saved {len(output)} samples to data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now since the data is prepared, we will train the model\n",
    "#this will give us the accuracy and confusion matrix for each emotion\n",
    "# Import necessary libraries for data preprocessing, model training, and evaluation\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split data\n",
    "data = np.loadtxt(\"data.txt\")\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = MLPClassifier(hidden_layer_sizes=(256, 128), max_iter=500, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\n Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred, target_names=[\n",
    "#     'Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise'\n",
    "# ]))\n",
    "\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "#             xticklabels=['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise'],\n",
    "#             yticklabels=['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise'])\n",
    "unique_labels = sorted(np.unique(y_test).astype(int))\n",
    "#We are just using the first five emotions from the cleaned dataset.\n",
    "emotion_map = {\n",
    "    0: 'Angry',\n",
    "    1: 'Disgust',\n",
    "    2: 'Fear',\n",
    "    3: 'Happy',\n",
    "    4: 'Neutral',\n",
    "    5: 'Sad',\n",
    "    6: 'Surprise'\n",
    "}\n",
    "target_names = [emotion_map[i] for i in unique_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results: accuracy and confusion matrix\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=target_names,\n",
    "            yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Emotion Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save model and scaler\n",
    "with open(\"model\", \"wb\") as f:\n",
    "    pickle.dump((scaler, model), f)\n",
    "\n",
    "print(\"Model and scaler saved as 'model'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_gpt_tip.py\n",
    "#this cell is responsible for getting the feedback from gpt based on the emotion detected using system prompting \n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env.local\")\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "def get_feedback_from_gpt(emotion):\n",
    "    system_prompt = \"You are a professional public speaking coach giving advice based on audience facial emotion. The topic being presented is Hawaiian beach. Give me suggestions based on the audience reachtion specific to the topic. For example, if the expression is Fear, mention an interesting fact about Hawaiian beach that can help the audience feel more comfortable. Give like two or three responses.\"\n",
    "    # system_prompt = \"You are a professional public speaking coach giving advice based on audience facial emotion. Give like two or three responses.\"\n",
    "    user_prompt = f\"The audience looks {emotion.lower()}. What should I say or do in my presentation?\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"HTTP-Referer\": \"https://your-site.com\",  # optional\n",
    "        \"X-Title\": \"Emotion-Based Feedback\"\n",
    "    }\n",
    "\n",
    "    json_data = {\n",
    "        \"model\": \"openai/gpt-3.5-turbo\",  # or another OpenRouter-supported model\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, json=json_data)\n",
    "    data = response.json()\n",
    "    return data['choices'][0]['message']['content']\n",
    "\n",
    "# Test\n",
    "if __name__ == \"__main__\":\n",
    "    emotion = input(\"Enter detected emotion: \")\n",
    "    tip = get_feedback_from_gpt(emotion)\n",
    "    print(\"\\nGPT Tip:\\n\", tip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "#this cell is reponsible for creating the GUI for the feedback\n",
    "class EmotionFeedbackGUI:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Live Emotion Feedback\")\n",
    "        self.label = tk.Label(self.root, text=\"Emotion: None\", font=(\"Arial\", 16))\n",
    "        self.label.pack()\n",
    "        self.feedback_box = tk.Text(self.root, wrap=tk.WORD, width=50, height=10)\n",
    "        self.feedback_box.pack()\n",
    "\n",
    "    def update_feedback(self, emotion, feedback):\n",
    "        self.label.config(text=f\"Emotion: {emotion}\")\n",
    "        self.feedback_box.delete(\"1.0\", tk.END)\n",
    "        self.feedback_box.insert(tk.END, feedback)\n",
    "\n",
    "    def run(self):\n",
    "        self.root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#This script is part of a real-time sentiment analysis project. It utilizes various libraries and modules \n",
    "#to perform tasks such as screen capturing, facial emotion analysis, and providing feedback through a GUI.\n",
    "\n",
    "\n",
    "import mss\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import textwrap\n",
    "from deepface import DeepFace\n",
    "from dotenv import load_dotenv\n",
    "from emotion_feedback_gui import EmotionFeedbackGUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dotenv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load GPT API key\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mload_dotenv\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.env.local\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENROUTER_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Setup GUI\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dotenv' is not defined"
     ]
    }
   ],
   "source": [
    "# Load GPT API key\n",
    "load_dotenv(\".env.local\")\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "# Setup GUI\n",
    "gui = EmotionFeedbackGUI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_feedback_from_gpt(emotion):\n",
    "    system_prompt = (\n",
    "        \"You are a professional public speaking coach. \"\n",
    "        \"Give a short tip (1-2 sentences) based on the audience's facial emotion. \"\n",
    "        \"Be supportive and give suggestions if the audience seems unengaged. \"\n",
    "        f\"The topic being presented is Hawaiian beach. If the audience looks {emotion}, tailor advice to that.\"\n",
    "    )\n",
    "    user_prompt = f\"The audience looks {emotion.lower()}. What should I say or do next in my presentation?\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"HTTP-Referer\": \"https://your-site.com\",\n",
    "        \"X-Title\": \"Live Emotion Feedback\"\n",
    "    }\n",
    "\n",
    "    json_data = {\n",
    "        \"model\": \"openai/gpt-3.5-turbo\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        res = requests.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, json=json_data)\n",
    "        res.raise_for_status()\n",
    "        return res.json()['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(\"GPT error:\", e)\n",
    "        return \"Unable to fetch suggestion.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def main():\n",
    "    with mss.mss() as sct:\n",
    "        monitor = sct.monitors[1]  # Full screen\n",
    "\n",
    "        while True:\n",
    "            screenshot = sct.grab(monitor)\n",
    "            frame = np.array(screenshot)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "            try:\n",
    "                result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
    "                emotion = result[0]['dominant_emotion']\n",
    "                print(f\"\\nDetected Emotion: {emotion}\")\n",
    "                suggestion = get_feedback_from_gpt(emotion)\n",
    "                print(f\"GPT Suggestion:\\n{textwrap.fill(suggestion, width=80)}\\n\")\n",
    "                \n",
    "                # FIXED: Run GUI update safely in main thread\n",
    "                gui.root.after(0, gui.update_feedback, emotion, suggestion)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"DeepFace failed:\", e)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gui.root.after(100, main)  # Schedule emotion loop\n",
    "    gui.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
